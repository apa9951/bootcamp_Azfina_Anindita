{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964a9eb6",
   "metadata": {},
   "source": [
    "## Student Homework Sheet — Stage 04: Data\n",
    "## Acquisition and Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00d8e757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded APLHAVANTAGE_API_KEY? True\n",
      "test_API_Azfina\n"
     ]
    }
   ],
   "source": [
    "#API PULL\n",
    "\n",
    "import os, json, time, datetime as dt, csv, pathlib\n",
    "from typing import Dict, List\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#pathlib = library utk pilih direktori folder\n",
    "DATA_RAW = pathlib.Path(\"data/raw\")\n",
    "\n",
    "#mkdir untuk bikin folder\n",
    "DATA_RAW.mkdir(parents=True, exist_ok= True)\n",
    "\n",
    "load_dotenv()\n",
    "ALPHA_KEY = os.getenv(\"ALPHAVANTAGE_API_KEY\")\n",
    "print(\"Loaded APLHAVANTAGE_API_KEY?\", bool(ALPHA_KEY))\n",
    "\n",
    "#print isi API nya\n",
    "print(ALPHA_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ca8d34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Symbol                        Name                    Price   Change  \\\n",
      "0   OPEN  Opendoor Technologies Inc.    3.1700+0.1300(+4.28%)  +0.1300   \n",
      "1   INTC           Intel Corporation       24.56+0.70(+2.93%)    +0.70   \n",
      "2   NVDA          NVIDIA Corporation      180.45-1.57(-0.86%)    -1.57   \n",
      "3     NU            Nu Holdings Ltd.       13.10+1.09(+9.08%)    +1.09   \n",
      "4   WULF               TeraWulf Inc.        8.97+0.26(+2.99%)    +0.26   \n",
      "\n",
      "  Change %    Volume Avg Vol (3M) Market Cap P/E Ratio(TTM) 52 WkChange %  \\\n",
      "0   +4.28%  410.691M     194.061M     2.333B             --       +69.83%   \n",
      "1   +2.93%  307.455M      87.982M   107.499B             --       +14.33%   \n",
      "2   -0.86%  150.295M     183.388M     4.401T          58.40       +46.11%   \n",
      "3   +9.08%  130.401M      61.716M      63.2B          29.77       -14.76%   \n",
      "4   +2.99%  107.212M      50.714M     3.516B             --      +116.13%   \n",
      "\n",
      "  52 Wk Range  \n",
      "0              \n",
      "1              \n",
      "2              \n",
      "3              \n",
      "4              \n"
     ]
    }
   ],
   "source": [
    "#SCRAPE A SMALL TABLE\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Yahoo Finance Most Active Stocks page\n",
    "url = \"https://finance.yahoo.com/most-active\"\n",
    "\n",
    "# Request the page\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Pretend to be a browser\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Parse with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Find the table\n",
    "table = soup.find(\"table\")  # Yahoo's first table on the page\n",
    "\n",
    "# Extract data\n",
    "rows = []\n",
    "for tr in table.find_all(\"tr\"):\n",
    "    cells = [td.get_text(strip=True) for td in tr.find_all([\"td\", \"th\"])]\n",
    "    if cells:\n",
    "        rows.append(cells)\n",
    "\n",
    "# Assume first row is header\n",
    "header, *data = rows\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=header)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "#save to CSV in data/raw\n",
    "df.to_csv(\"data/raw/api_yahoo_most_active_stocks_20250815_2030.csv\", index=False)\n",
    " \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29b8a440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data from Alpha Vantage API\n",
      "         date      Open      High       Low     Close    Volume\n",
      "0  2025-08-15  234.0000  234.2800  229.3350  231.5900  54908236\n",
      "1  2025-08-14  234.0550  235.1200  230.8500  232.7800  51916275\n",
      "2  2025-08-13  231.0700  235.0000  230.4300  233.3300  69878546\n",
      "3  2025-08-12  228.0050  230.8000  227.0700  229.6500  55672301\n",
      "4  2025-08-11  227.9200  229.5600  224.7600  227.1800  61806132\n"
     ]
    }
   ],
   "source": [
    "#BEAUTIFUL SOUP\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# --- SETTINGS ---\n",
    "symbol = \"AAPL\"  # Example: Apple\n",
    "ALPHA_KEY = \"YOUR_ALPHA_VANTAGE_API_KEY\"\n",
    "\n",
    "# --- TRY ALPHA VANTAGE FIRST ---\n",
    "try:\n",
    "    url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY&symbol={symbol}&apikey={ALPHA_KEY}\"\n",
    "    r = requests.get(url, timeout=20)\n",
    "    r.raise_for_status()\n",
    "    js = r.json()\n",
    "\n",
    "    key = [k for k in js.keys() if \"Time Series\" in k]\n",
    "    assert key, f\"Unexpected response keys: {list(js.keys())}\"\n",
    "\n",
    "    series = js[key[0]]\n",
    "    df_api = (\n",
    "        pd.DataFrame(series).T\n",
    "        .rename_axis(\"date\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            \"1. open\": \"Open\",\n",
    "            \"2. high\": \"High\",\n",
    "            \"3. low\": \"Low\",\n",
    "            \"4. close\": \"Close\",\n",
    "            \"5. volume\": \"Volume\"\n",
    "        })\n",
    "    )\n",
    "\n",
    "    print(\"✅ Data from Alpha Vantage API\")\n",
    "    print(df_api.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"⚠ API failed, falling back to Yahoo Finance scrape:\", e)\n",
    "\n",
    "    # --- FALLBACK: SCRAPE YAHOO FINANCE ---\n",
    "    scrape_url = f\"https://finance.yahoo.com/quote/{symbol}/history\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    \n",
    "    resp = requests.get(scrape_url, headers=headers, timeout=20)\n",
    "    resp.raise_for_status()\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    table = soup.find(\"table\")\n",
    "    \n",
    "    rows = []\n",
    "    for tr in table.find_all(\"tr\"):\n",
    "        cells = [td.get_text(strip=True) for td in tr.find_all([\"td\", \"th\"])]\n",
    "        if cells:\n",
    "            rows.append(cells)\n",
    "    \n",
    "    header, *data = rows\n",
    "    df_scrape = pd.DataFrame(data, columns=header)\n",
    "\n",
    "    print(\"✅ Data from Yahoo Finance scraping\")\n",
    "    print(df_scrape.head())\n",
    "\n",
    "\n",
    "#save result to CSV in data/raw\n",
    "df.to_csv(\"data/raw/scrape_alphavantage_most_active_stocks_20250815_2030\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebfd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
